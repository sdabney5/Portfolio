{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2582d582",
   "metadata": {},
   "source": [
    "# Linear Regression w/ Gradient Descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03829056",
   "metadata": {},
   "source": [
    "## Section 1 - Background:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854b3ccc",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In Linear Regression we try to fit a line, or a plane, or a hyperplane to data. We can do this by calcuating the best coefficient values for the hypothesis function. The \"best\" values are those that minimize the error of our predictions (difference between predicted valued and actual values).\n",
    "\n",
    "My objective in this project is to code a Linear Regression function from scratch without using python libraries. This will likely result in cumbersome, less-efficient code. However, it will truly be from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a622b2c",
   "metadata": {},
   "source": [
    "### Hypothesis Function\n",
    "\n",
    "___\n",
    "\n",
    "One approach is to describe the function in a way that treats weights and bias separately:\n",
    "\n",
    "$$ \\hat{y} = \\beta + w*x$$\n",
    "\n",
    "___\n",
    "A slightly different approach, and the one I take here, involves treating bias and weights as values in the same vector, $\\vec{\\theta}$ . We can do this by adding a column of 1's to the $x$ matrix to represent $x_{0}$. This allows us to describe the function as:\n",
    "\n",
    "\n",
    "$$ h_{\\theta} (x) = \\theta_{0} x_{0} + \\theta_{1} x_{1}+\\theta_{2} x_{2}...\\theta_{n} x_{n}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$ \\theta_{0}$ gets a $ x_{0}$ (where $ x_{0} = 1$) so that we can take the inner product of the $\\theta$ vector ($\\vec{\\theta}$) and the $x$ vector  ($\\vec{x}$) and describe the hypothesis function as:\n",
    "\n",
    "$$  h_{\\theta} (x) = \\vec{\\theta^{\\top}} \\vec{x} $$\n",
    "\n",
    "**Note:  \n",
    "To take the inner product (dot product), we need to transpose $\\vec{\\theta}$ so that the number of columns in $\\vec{\\theta}$ matches the number of rows in $\\vec{x}$. However, the code below simply uses for loops to iterate through the x matrix and make calculations at each location. So theta will technically not need to be transposed like it would if I used Numpy to perform matrix multiplication.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a202cad",
   "metadata": {},
   "source": [
    "### The Mean Squared Error (MSE) Loss Function:\n",
    "\n",
    "$$ MSE = J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})^2 $$\n",
    "\n",
    "* $m$ is the number of training samples <br>\n",
    "* $x^{(i)}$ is the $i$th input feature vector (values of $x$ for each column $j$ for the $i$th row)<br>\n",
    "* $y^{(i)}$ is the corresponding observed value<br>\n",
    "* $h_\\theta(x^{(i)})$ is the hypothesis function for the $i$th training example<br>\n",
    "* $\\theta$ is the weights (parameters) vector.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc97c498",
   "metadata": {},
   "source": [
    "## Minimize the Loss Function\n",
    "##### Our hypothesis function needs the values of $\\theta$ that minimize error.  \n",
    "\n",
    "\n",
    "### Closed Form Solution\n",
    "One way to calculate the values of $\\theta$ that minimize error is to use the \"closed form solution\":\n",
    "\n",
    "$$\\theta = (X^TX)^{-1}X^Ty$$\n",
    ">Where:\n",
    "> * $\\theta$ is the vector of regression coefficients  \n",
    "> * $X$ is the matrix of input features  \n",
    "> * $y$ is the vector of observed valued  \n",
    "> * $X^T$ is the transpose of $X$  \n",
    "> * $(X^TX)^{-1}$ is the inverse of the matrix $X^TX$.\n",
    "\n",
    "**However:**   \n",
    "Using the closed form solution can be computationally expensive since it involves inverting the $X$ matrix, which involves computing the determinant and adjugate. For large matrices this might not be a good approach. **I will not use the closed form solution here.**\n",
    "\n",
    "___\n",
    "___\n",
    "___\n",
    "\n",
    "### Gradient Descent\n",
    "\n",
    "Another way to accomplish this is to use gradient descent. This means using an iterative algorithm that calculates the gradient of the loss function with respect to each theta value. This tells us the direction of the steepest ascent. We can then update the $\\theta$ values in the opposite direction, by some specified amount, for a specified number of iterations.  \n",
    "\n",
    "\n",
    "> Note:\n",
    "> The MSE function is parabolic, since it has a quadratic form. This means it will have a minimum or maximum where all partial > derivatives of MSE are equal to 0. This means that when we get close to the minimum, it is the actual minimum. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c465b4",
   "metadata": {},
   "source": [
    "### Partial Derivatives of the MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8792c98",
   "metadata": {},
   "source": [
    "We need the values of $\\theta$ that minimuze the Loss Function. This means trying to find where the partial derivates of the MSE equal 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94535f46",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We can get the partial derivative of $J(\\theta)$ with respect to $\\theta_j$ by using the *chain rule*.\n",
    "___\n",
    "\n",
    "First, we get the derivative of the MSE loss with respect to the hypothesis function: $h_\\theta(x^{(i)})$. We get:   \n",
    "  \n",
    "$$ \\frac{\\partial J}{\\partial h_\\theta(x^{(i)})} = \\frac{1}{m}(h_\\theta(x^{(i)}) - y^{(i)}) $$\n",
    "  \n",
    "*note: the \"2\" in the denominator of the MSE cancels*\n",
    "___\n",
    "\n",
    "Then we get the derivative of the hypothesis function $h_\\theta(x^{(i)})$ with respect to  $\\theta_j$:  \n",
    "$$ \\frac{\\partial h_\\theta(x^{(i)})}{\\partial \\theta_j} = x_j^{(i)} $$\n",
    "___\n",
    "\n",
    "Now we multiply the two derivatives (chain rule) to get the partial derivative of $J(\\theta)$ with respect to $\\theta_j$ :\n",
    "$$ \\frac{\\partial J}{\\partial \\theta_j} = \\frac{\\partial J}{\\partial h_\\theta(x^{(i)})} * \\frac{\\partial h_\\theta(x^{(i)})}{\\partial \\theta_j} = \\frac{1}{m}(h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} $$\n",
    "___\n",
    "Now sum over all $m$ training examples:\n",
    "$$ \\frac{\\partial J}{\\partial \\theta_j} = \\frac{1}{m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} $$\n",
    "___\n",
    "So, the partial derivative of the MSE respect to $\\theta_j$ is:\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial \\theta_j} = \\frac{1}{m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a2a1e0",
   "metadata": {},
   "source": [
    "*An aside to myself:\n",
    "The upshot of this is that, to get the partial derivative of the loss function with respect to $\\theta_j$, the calculation works out so that the answer at each sample is just the error multiplied by the value at the jth column for that row. Sum this value for each row and that is the gradient of the loss function at $\\theta_j$. Easy.* \n",
    "\n",
    "*This also means that the calculation for [j] thetas involves calculating the error for each of m samples, multiplying each error by some value, summing them, and doing all of this [j] times for each iteration. This might take a while, depending on the sizes of m and j.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc8f41",
   "metadata": {},
   "source": [
    "## Update thetas in the opposite direction of ascent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e312b3",
   "metadata": {},
   "source": [
    "Values of $\\theta$ need to be updated to reflect the direction of descent toward the minimum of the MSE. \n",
    "\n",
    "We do this by assigning (\":=\") the next $\\theta$ to a new value, determined by the gradient which will be positive or negative. We take a fraction of the gradient (given by $\\alpha$ or the \"learning rate\") and subtract that from $\\theta$ to get the new value for $\\theta$:\n",
    "\n",
    "$\\theta_{j-new} := \\theta_{j-old} - \\alpha*\\frac{\\partial}{\\partial \\theta_j} J(\\theta)$\n",
    "\n",
    "___\n",
    "\n",
    "Each $\\theta$ is updated as many times as specified by the given number of iterations. At the end, if alpha was not too big or too small, we should be at or very very near the minimum.\n",
    "\n",
    "We then have the appropriate $\\theta$ values to use in our hypothesis function. This means we can make predictions for new $x$ values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775595b9",
   "metadata": {},
   "source": [
    ">Something to note:\n",
    "The MSE as I wrote it above calculates the error as $\\hat{y} - y$. \n",
    "If instead we calculated the error as $y - \\hat{y}$, then I beleive we would *add* the fraction of the derivative to the old $\\theta_{j}$ value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fabe47",
   "metadata": {},
   "source": [
    "# Section 2: Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec9f5e5",
   "metadata": {},
   "source": [
    "In this code I attempted to create a LinearRegression class that uses gradient descent to find the best values for the vector $\\theta$, as described above. After initializing the hyperparameters of the model, a fit method trains the model on the given data \"X\", and a predict method makes predictions on new data using the values of $\\theta$ obtained by gradient descent during the fit method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fbd6c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \n",
    "    #initialize hyperparameters\n",
    "    def __init__(self, alpha = 0.001, num_iterations = 1000):\n",
    "        self.alpha = alpha\n",
    "        self.num_iterations = num_iterations\n",
    "        self.theta = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Add a column of 1's to X to represent the intercept\n",
    "        X = X.insert(0, \"ONES\", 1) \n",
    "        \n",
    "        # Rows (m) and columns (n)\n",
    "        m , n = X.shape\n",
    "        \n",
    "        # Initialize a list of 0's length \"n\" for first theta values\n",
    "        self.theta = [0]*n         \n",
    "        \n",
    "        #Hypothesis function\n",
    "        for _ in range(self.num_iterations):\n",
    "            # Create a 0's list of predicted values for y_hat\n",
    "            y_hat = [0]*m \n",
    "            for i in range(m):\n",
    "                 for j in range(n):\n",
    "                        y_hat[i] += (X[i][j] * self.theta[j])  #this is the hypothesis function.\n",
    "                        \n",
    "                \n",
    "            #Gradient calculation of MSE (J(theta)) w.r.t. theta[j]\n",
    "            dJ_dtheta = [0]*n \n",
    "            \n",
    "            for j in range(n):\n",
    "                for i in range(m):\n",
    "                    dJ_dtheta[j] += 1/m * ((y_hat[i] - y[i]) * X[i][j]) # The partial derivative of the MSE w.r.t theta[j]\n",
    "                    \n",
    "             \n",
    "            #update theta values\n",
    "            for j in range(n):\n",
    "                self.theta[j] -=  self.alpha * dJ_dtheta[j]\n",
    "            \n",
    "    def predict(self, X):\n",
    "        #Add a column of 1's to X to represent the intercept\n",
    "        X = X.insert(0, \"ONES\", 1) \n",
    "        \n",
    "        # Rows (m) and columns (n)\n",
    "        m , n = X.shape \n",
    "        \n",
    "        #Create a list of zeros for predictions corresponding to each row\n",
    "        y_prediction = [0]*m \n",
    "        \n",
    "        #Compute predictions\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                y_prediction[i] += X[i][j] * self.theta[j]\n",
    "        return y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798a1c25",
   "metadata": {},
   "source": [
    "## Insights and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857127e9",
   "metadata": {},
   "source": [
    "Overall I learned quite a bit by building this. However, I am also aware that there are many many ways to improve.\n",
    "\n",
    "For example, using libraries like Numpy to perform dot product calculations could make the code more efficient. I only avoided using libraries to gain a more complete understanding, but I may now build another class using Numpy.Additionally, I think it might be useful to add functionality to store the gradients as they are calculated. This would allow us to plot the loss function for each iteration to verify that it is being minimized with the updated theta values. \n",
    "\n",
    "In future versions, I plan to add options (or create separate classes for) regularization, including l1 (lasso), l2 (ridge), and elastic net. This will allow for better control over model complexity and possibly reduce overfitting. I may also explore other optimization techniques. Here, I used \"batch\" gradient descent, but there are other algorithms (like stochastic gradient descent) that may work faster or with fewer iterations. Batch gradient descent will work fine, but might take too long with very large data sets, since it has to go through all values in the X matrix for each iteration.\n",
    "\n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe2d074",
   "metadata": {},
   "source": [
    "### Sources\n",
    "**Math Sources**  \n",
    "\n",
    "https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf\n",
    "\n",
    "https://datascience.stackexchange.com/questions/29526/why-is-there-a-2-at-the-denominator-of-the-mean-squared-error-function#:~:text=This%20is%20just%20for%20mathematical,is%20kept%20beforehand%20in%20denominator.\n",
    "\n",
    "https://www.internalpointers.com/post/introduction-machine-learning\n",
    "\n",
    "https://stackoverflow.com/questions/17289082/gradient-descent-convergence-how-to-decide-convergence\n",
    "\n",
    "https://math.libretexts.org/Bookshelves/Calculus/Book%3A_Calculus_(OpenStax)/14%3A_Differentiation_of_Functions_of_Several_Variables/14.05%3A_The_Chain_Rule_for_Multivariable_Functions\n",
    "\n",
    "\n",
    "\n",
    "**Markdown Help**  \n",
    "https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd\n",
    "\n",
    "https://medium.com/analytics-vidhya/writing-math-equations-in-jupyter-notebook-a-naive-introduction-a5ce87b9a214\n",
    "\n",
    "\n",
    "**Coding Resources**  \n",
    "https://stackoverflow.com/questions/35208160/dot-product-in-python-without-numpy\n",
    "\n",
    "\n",
    "**Video Resources:** \n",
    "\n",
    "Chain Rule:  \n",
    "https://youtu.be/tXryaM-mTpY\n",
    "https://www.youtube.com/watch?v=XipB_uEexF0\n",
    "\n",
    "Machine Learning Course:  \n",
    "https://www.youtube.com/watch?v=4b4MUYve_U8\n",
    "\n",
    "Linear Algebra Course  \n",
    "https://youtube.com/playlist?list=PLl-gb0E4MII03hiCrZa7YqxUMEeEPmZqK\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd396ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a93883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
